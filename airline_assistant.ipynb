{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ad8048d",
   "metadata": {},
   "source": [
    "## Project - Airline AI Assistant\n",
    "\n",
    "We'll now bring together what we've learned to make an AI Customer Support assistant for an Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1a722840",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import anthropic as ant\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1210883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key exists and begins sk-ant-\n",
      "Google API Key exists and begins AI\n"
     ]
    }
   ],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "API_KEYS = {\n",
    "    \"OpenAI\": (\"OPENAI_API_KEY\", 8),\n",
    "    \"Anthropic\": (\"ANTHROPIC_API_KEY\", 7),\n",
    "    \"Google\": (\"GOOGLE_API_KEY\", 2)\n",
    "}\n",
    "\n",
    "keys = {label: os.getenv(env) for label, (env, _) in API_KEYS.items()}\n",
    "\n",
    "def check_key(label, prefix_len):\n",
    "    key = keys[label]\n",
    "    if key:\n",
    "        print(f\"{label} API Key exists and begins {key[:prefix_len]}\")\n",
    "    else:\n",
    "        print(f\"{label} API Key not set (optional)\")\n",
    "\n",
    "for label, (env_name, prefix_len) in API_KEYS.items():\n",
    "    check_key(label, prefix_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a53141e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai  = OpenAI(api_key=keys[\"OpenAI\"])\n",
    "anthropic = ant.Anthropic(api_key=keys[\"Anthropic\"])\n",
    "genai.configure(api_key=keys[\"Google\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f4243823",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tokens = 512\n",
    "gpt_model = \"gpt-4o-mini\"\n",
    "claude_model = \"claude-3-haiku-20240307\"\n",
    "gemini_model = \"models/gemini-2.0-flash\"\n",
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant for an Airline called FlightAI.\n",
    "Give short, courteous answers, no more than 1 sentence.\n",
    "Always be accurate. If you don't know the answer, say so.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77f51b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gpt(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    yield response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b2e807db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_claude(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = anthropic.messages.create(\n",
    "        model=claude_model,\n",
    "        system=system_prompt,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens\n",
    "    )\n",
    "    yield response.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6ae747f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_gemini(message, history):\n",
    "    gemini_history = []\n",
    "    \n",
    "    # 1. Convert history from OpenAI format to Gemini format\n",
    "    for h in history:\n",
    "        # Map 'assistant' to 'model', 'user' stays the same\n",
    "        role = \"model\" if h[\"role\"] == \"assistant\" else \"user\"\n",
    "        \n",
    "        # Ignore system messages\n",
    "        if h[\"role\"] == \"system\":\n",
    "            continue\n",
    "            \n",
    "        content = h[\"content\"]\n",
    "        \n",
    "        # If 'content' is a list (Gradio multimodal format), we extract only the text\n",
    "        if isinstance(content, list):\n",
    "            # We join all the parts that are text.\n",
    "            content = \" \".join([part[\"text\"] for part in content if \"text\" in part])\n",
    "        \n",
    "        # Now 'content' is safely a string\n",
    "        gemini_history.append({\n",
    "            \"role\": role,\n",
    "            \"parts\": [content]\n",
    "        })\n",
    "    \n",
    "    # 2. Add the user's current message\n",
    "    gemini_history.append({\n",
    "        \"role\": \"user\",\n",
    "        \"parts\": [message]\n",
    "    })\n",
    "\n",
    "    config = genai.types.GenerationConfig(\n",
    "        max_output_tokens=max_tokens,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    model = genai.GenerativeModel(\n",
    "        model_name=gemini_model,\n",
    "        system_instruction=system_prompt\n",
    "    )\n",
    "\n",
    "    # 3. Transfer the complete list\n",
    "    response = model.generate_content(gemini_history, generation_config=config)\n",
    "    \n",
    "    yield response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c5d8712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7900\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7900/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat_claude).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0b29489",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_manager(message, history, model_name):\n",
    "    \n",
    "    if model_name == \"Gemini\":\n",
    "        yield from chat_gemini(message, history)\n",
    "        \n",
    "    elif model_name == \"GPT-4o\":\n",
    "        yield from chat_gpt(message, history)\n",
    "        \n",
    "    elif model_name == \"Claude 3\":\n",
    "        yield from chat_claude(message, history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8bc8f607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7898\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7898/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dropdown = gr.Dropdown(\n",
    "    choices=[\"Gemini\", \"GPT-4o\", \"Claude 3\"], \n",
    "    value=\"Gemini\", \n",
    "    label=\"Select the Model\"\n",
    ")\n",
    "\n",
    "gr.ChatInterface(\n",
    "    fn=chat_manager,\n",
    "    additional_inputs=[model_dropdown],\n",
    "    title=\"ðŸ¤– Multi-Model Chat\",\n",
    "    description=\"Chat with different AIs by changing the selector below.\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1c509e",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are an incredibly powerful feature provided by the frontier LLMs.\n",
    "\n",
    "With tools, you can write a function, and have the LLM call that function as part of its response.\n",
    "\n",
    "Sounds almost spooky.. we're giving it the power to run code on our machine?\n",
    "\n",
    "Well, kinda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b7cd5262",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool called for city {destination_city}\")\n",
    "    price = ticket_prices.get(destination_city.lower(), \"Unknown ticket price\")\n",
    "    return f\"The price of a ticket to {destination_city} is {price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ed501dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The price of a ticket to London is $799'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "aee7f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\",\n",
    "            },\n",
    "        },\n",
    "        \"required\": [\"destination_city\"],\n",
    "        \"additionalProperties\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7cdd5b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "tools = [{\"type\": \"function\", \"function\": price_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b240278",
   "metadata": {},
   "source": [
    "## Getting OpenAI to use our Tool\n",
    "\n",
    "There's some fiddly stuff to allow OpenAI \"to call our tool\"\n",
    "\n",
    "What we actually do is give the LLM the opportunity to inform us that it wants us to run the tool.\n",
    "\n",
    "Here's how the new chat function looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a7ed1548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call(message):\n",
    "    tool_call = message.tool_calls[0]\n",
    "    if tool_call.function.name == \"get_ticket_price\":\n",
    "        arguments = json.loads(tool_call.function.arguments)\n",
    "        city = arguments.get('destination_city')\n",
    "        price_details = get_ticket_price(city)\n",
    "        response = {\n",
    "            \"role\": \"tool\",\n",
    "            \"content\": price_details,\n",
    "            \"tool_call_id\": tool_call.id\n",
    "        }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "30bbd24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    response = openai.chat.completions.create(model=gpt_model, messages=messages, tools=tools)\n",
    "\n",
    "    if response.choices[0].finish_reason==\"tool_calls\":\n",
    "        message = response.choices[0].message\n",
    "        response = handle_tool_call(message)\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        response = openai.chat.completions.create(model=gpt_model, messages=messages)\n",
    "    \n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e254e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7904\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7904/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool called for city London\n",
      "Tool called for city Tokyo\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
